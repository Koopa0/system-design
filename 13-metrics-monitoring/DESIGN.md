# Metrics Monitoring ç³»çµ±è¨­è¨ˆæ–‡æª”

## é›™11å‡Œæ™¨çš„å™©å¤¢

2024 å¹´ 11 æœˆ 11 æ—¥å‡Œæ™¨ 00:00ï¼Œé›»å•†å¹³å°ã€Œå¿«æ¨‚è³¼ã€çš„é›™11æ´»å‹•æ­£å¼é–‹å§‹ã€‚

SRE å·¥ç¨‹å¸« Sarah ååœ¨ç›£æ§å®¤ï¼Œç›¯è‘—å„€è¡¨æ¿ã€‚

**00:01** - è¨‚å–®é‡ï¼š127 ç­†/ç§’ï¼ˆæ­£å¸¸ï¼‰

**00:05** - è¨‚å–®é‡ï¼š1,894 ç­†/ç§’ï¼ˆæµé‡æ¿€å¢ï¼ï¼‰

**00:08** - Sarah çš„æ‰‹æ©Ÿæ”¶åˆ°ç”¨æˆ¶æŠ•è¨´ï¼šã€Œç¶²ç«™æ‰“ä¸é–‹ï¼ã€

å¥¹ç«‹åˆ»æ‰“é–‹æœå‹™å™¨æŸ¥çœ‹ï¼š

```bash
$ ssh web-server-01
$ top

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM
 1234 www       20   0   8.2g   6.8g   1.2g R  98.7 85.3

å•é¡Œï¼šæœå‹™å™¨ CPU 98%ï¼Œå…§å­˜ 85%ï¼
```

Sarah ç·Šæ€¥é‡å•Ÿäº†æœå‹™å™¨ï¼Œç¶²ç«™æ¢å¾©æ­£å¸¸ã€‚

ä½† 10 åˆ†é˜å¾Œï¼Œåˆæ”¶åˆ°æŠ•è¨´...

**å¥¹æ„è­˜åˆ°ä¸€å€‹åš´é‡å•é¡Œï¼šæˆ‘å€‘æ²’æœ‰ç›£æ§ç³»çµ±ï¼Œåªèƒ½é ç”¨æˆ¶æŠ•è¨´æ‰çŸ¥é“å‡ºå•é¡Œï¼**

---

**ç•¶æ™šçš„æå¤±æ•¸æ“šï¼š**
```
00:08 - 00:18ï¼ˆ10 åˆ†é˜å®•æ©Ÿï¼‰ï¼š
- æå¤±è¨‚å–®ï¼šä¼°è¨ˆ 11,364 ç­†
- æå¤±é‡‘é¡ï¼šç´„ NT$ 3,400 è¬
- ç”¨æˆ¶æµå¤±ï¼šç´„ 8,000 äºº

00:25 - 00:35ï¼ˆå†æ¬¡å®•æ©Ÿï¼‰ï¼š
- æå¤±è¨‚å–®ï¼šä¼°è¨ˆ 9,827 ç­†
- æå¤±é‡‘é¡ï¼šç´„ NT$ 2,900 è¬

ç¸½æå¤±ï¼šNT$ 6,300 è¬
```

ç¬¬äºŒå¤©æ—©ä¸Šçš„è¦†ç›¤æœƒè­°ä¸Šï¼ŒCTO å¤§ç™¼é›·éœ†ï¼š

ã€Œç‚ºä»€éº¼æ²’æœ‰ç›£æ§ï¼Ÿç‚ºä»€éº¼è¦ç­‰ç”¨æˆ¶æŠ•è¨´æ‰ç™¼ç¾å•é¡Œï¼Ÿã€

Sarah ä½è‘—é ­ï¼šã€Œæˆ‘å€‘... æ²’æœ‰ç›£æ§ç³»çµ±ã€‚ã€

ã€Œç«‹åˆ»å»ºç«‹ï¼ä¸‹æ¬¡é›™11ä¹‹å‰å¿…é ˆä¸Šç·šï¼ã€

## ç¬¬ä¸€æ¬¡å˜—è©¦ï¼šæ‰‹å‹•æª¢æŸ¥ï¼ˆ2024/11/12ï¼‰

### æœ€ç°¡å–®çš„æ–¹æ¡ˆ

Sarah çš„ç¬¬ä¸€å€‹æƒ³æ³•ï¼šå¯«å€‹è…³æœ¬å®šæœŸæª¢æŸ¥ã€‚

```bash
#!/bin/bash
# check_server.sh

while true; do
    # æª¢æŸ¥ CPU
    cpu=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)

    # æª¢æŸ¥å…§å­˜
    mem=$(free | grep Mem | awk '{print ($3/$2) * 100.0}')

    # æª¢æŸ¥ç£ç›¤
    disk=$(df -h / | tail -1 | awk '{print $5}' | cut -d'%' -f1)

    echo "[$(date)] CPU: ${cpu}%, MEM: ${mem}%, DISK: ${disk}%"

    # å¦‚æœ CPU > 80%ï¼Œç™¼éƒµä»¶å‘Šè­¦
    if (( $(echo "$cpu > 80" | bc -l) )); then
        echo "CPU éé«˜ï¼" | mail -s "å‘Šè­¦" sarah@example.com
    fi

    sleep 60  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
done
```

ã€Œç”¨ cron æ¯åˆ†é˜åŸ·è¡Œä¸€æ¬¡ï¼Œæ‡‰è©²å¤ äº†å§ï¼Ÿã€Sarah æƒ³ã€‚

### å•é¡Œå¾ˆå¿«å‡ºç¾

**å•é¡Œ 1ï¼šæ­·å²æ•¸æ“šç¼ºå¤±**
```
2024-11-15 03:00 - CPU: 78%
2024-11-15 03:01 - CPU: 82%ï¼ˆå‘Šè­¦ï¼ï¼‰
2024-11-15 03:02 - CPU: 45%

å•é¡Œï¼š
- åªæœ‰ç•¶å‰æ™‚åˆ»çš„æ•¸æ“š
- ç„¡æ³•æŸ¥çœ‹è¶¨å‹¢ï¼ˆéå»ä¸€å°æ™‚ã€éå»ä¸€å¤©ï¼‰
- ç„¡æ³•åˆ†ææ ¹å› ï¼ˆCPU çªç„¶å‡é«˜æ˜¯ä»€éº¼å°è‡´çš„ï¼Ÿï¼‰
```

**å•é¡Œ 2ï¼šå¤šå°æœå‹™å™¨**
```
æœ‰ 20 å° Web æœå‹™å™¨ï¼Œéœ€è¦ï¼š
- ç™»å…¥æ¯å°æœå‹™å™¨åŸ·è¡Œè…³æœ¬
- æ”¶é›† 20 å°çš„æ•¸æ“š
- æ‰‹å‹•å½™ç¸½åˆ†æ âŒ

å¤ªéº»ç…©äº†ï¼
```

**å•é¡Œ 3ï¼šæŒ‡æ¨™å–®ä¸€**
```
åªç›£æ§ CPUã€å…§å­˜ã€ç£ç›¤ï¼Œä½†é‚„éœ€è¦ï¼š
- HTTP è«‹æ±‚æ•¸ï¼ˆQPSï¼‰
- éŸ¿æ‡‰æ™‚é–“ï¼ˆå»¶é²ï¼‰
- éŒ¯èª¤ç‡
- æ•¸æ“šåº«é€£æ¥æ•¸
- å¿«å–å‘½ä¸­ç‡
- ...

æ¯åŠ ä¸€å€‹æŒ‡æ¨™ï¼Œè…³æœ¬è®Šå¾—æ›´è¤‡é›œ
```

Sarah å˜†æ°£ï¼šã€Œé€™æ¨£ä¸‹å»ä¸è¡Œï¼Œéœ€è¦ä¸€å€‹å°ˆé–€çš„ç›£æ§ç³»çµ±ã€‚ã€

## ç¬¬äºŒæ¬¡å˜—è©¦ï¼šå¯«å…¥æ•¸æ“šåº«ï¼ˆ2024/11/16ï¼‰

### æ€è·¯

ã€ŒæŠŠæŒ‡æ¨™æ•¸æ“šå­˜å…¥æ•¸æ“šåº«ï¼Œç„¶å¾Œç”¨ SQL æŸ¥è©¢ï¼ã€

```sql
CREATE TABLE metrics (
    id SERIAL PRIMARY KEY,
    metric_name VARCHAR(100),
    metric_value FLOAT,
    host VARCHAR(50),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ¯ç§’æ’å…¥ä¸€æ¬¡
INSERT INTO metrics (metric_name, metric_value, host)
VALUES ('cpu_usage', 78.5, 'web-server-01');

INSERT INTO metrics (metric_name, metric_value, host)
VALUES ('memory_usage', 65.2, 'web-server-01');
```

### å•é¡Œï¼šæ•¸æ“šé‡çˆ†ç‚¸

**è¨ˆç®—ï¼š**
```
å ´æ™¯ï¼š
- 20 å°æœå‹™å™¨
- æ¯å° 10 å€‹æŒ‡æ¨™ï¼ˆCPUã€å…§å­˜ã€ç£ç›¤ã€QPSã€å»¶é²...ï¼‰
- æ¯ç§’æ¡é›†ä¸€æ¬¡

æ•¸æ“šé‡ï¼š
- æ¯ç§’ï¼š20 Ã— 10 = 200 æ¢è¨˜éŒ„
- æ¯åˆ†é˜ï¼š200 Ã— 60 = 12,000 æ¢
- æ¯å°æ™‚ï¼š12,000 Ã— 60 = 720,000 æ¢
- æ¯å¤©ï¼š720,000 Ã— 24 = 17,280,000 æ¢ï¼ˆ1,728 è¬ï¼‰
- æ¯æœˆï¼š1,728 è¬ Ã— 30 = 5.184 å„„æ¢ âŒ

å­˜å„²ï¼š
- æ¯æ¢è¨˜éŒ„ç´„ 100 bytes
- æ¯æœˆï¼š5.184 å„„ Ã— 100 bytes = 51.84 GB

ä¸€å¹´ï¼š51.84 Ã— 12 = 622 GBï¼
```

**æ€§èƒ½å•é¡Œï¼š**
```sql
-- æŸ¥è©¢éå» 1 å°æ™‚çš„å¹³å‡ CPU
SELECT AVG(metric_value) as avg_cpu
FROM metrics
WHERE metric_name = 'cpu_usage'
  AND host = 'web-server-01'
  AND timestamp >= NOW() - INTERVAL '1 hour';

åŸ·è¡Œæ™‚é–“ï¼š8.7 ç§’ âŒï¼ˆæƒæ 72 è¬æ¢è¨˜éŒ„ï¼‰

-- æŸ¥è©¢éå» 24 å°æ™‚ï¼Œæ¯åˆ†é˜çš„å¹³å‡ CPUï¼ˆ1440 å€‹é»ï¼‰
SELECT
    DATE_TRUNC('minute', timestamp) as time,
    AVG(metric_value) as avg_cpu
FROM metrics
WHERE metric_name = 'cpu_usage'
  AND host = 'web-server-01'
  AND timestamp >= NOW() - INTERVAL '24 hours'
GROUP BY DATE_TRUNC('minute', timestamp)
ORDER BY time;

åŸ·è¡Œæ™‚é–“ï¼š35.2 ç§’ âŒï¼ˆæƒæ 1,728 è¬æ¢è¨˜éŒ„ï¼‰
```

Sarah å´©æ½°äº†ï¼šã€ŒæŸ¥è©¢å¤ªæ…¢äº†ï¼è€Œä¸”æ•¸æ“šé‡é‚„åœ¨ä¸æ–·å¢é•·...ã€

### ç‚ºä»€éº¼å‚³çµ±æ•¸æ“šåº«ä¸é©åˆï¼Ÿ

è³‡æ·± DBA Mike è§£é‡‹ï¼š

ã€Œæ™‚åºæ•¸æ“šï¼ˆTime-Series Dataï¼‰æœ‰ç‰¹æ®Šæ€§è³ªï¼šã€

```
1. å¯«å…¥é »ç¹ï¼ˆæ¯ç§’æ•¸ç™¾æ¬¡ï¼‰
   - PostgreSQL é‡å° OLTP å„ªåŒ–ï¼ˆå°‘é‡å¯«å…¥ + è¤‡é›œæŸ¥è©¢ï¼‰
   - ä¸é©åˆé«˜é »æ™‚åºå¯«å…¥

2. åªè¿½åŠ ï¼ˆAppend-Onlyï¼‰
   - æŒ‡æ¨™æ•¸æ“šåªæœƒæ–°å¢ï¼Œä¸æœƒä¿®æ”¹
   - PostgreSQL çš„ MVCCï¼ˆå¤šç‰ˆæœ¬ä¸¦ç™¼æ§åˆ¶ï¼‰æ˜¯æµªè²»

3. æ™‚é–“ç¯„åœæŸ¥è©¢
   - ç¸½æ˜¯æŸ¥è©¢æŸå€‹æ™‚é–“ç¯„åœï¼ˆå¦‚éå» 1 å°æ™‚ï¼‰
   - PostgreSQL çš„ B-Tree ç´¢å¼•ä¸å¤ é«˜æ•ˆ

4. èšåˆè¨ˆç®—
   - éœ€è¦å¤§é‡ AVGã€SUMã€MAXã€MINã€P99
   - PostgreSQL çš„èšåˆéœ€è¦æƒæå¤§é‡æ•¸æ“š

5. èˆŠæ•¸æ“šå¯åˆªé™¤
   - é€šå¸¸åªä¿ç•™æœ€è¿‘ 30 å¤©çš„è©³ç´°æ•¸æ“š
   - æ›´æ—©çš„æ•¸æ“šå¯ä»¥åˆªé™¤æˆ–é™æ¡æ¨£
   - PostgreSQL çš„ DELETE æ€§èƒ½å·®
```

ã€Œä½ éœ€è¦çš„æ˜¯**æ™‚åºæ•¸æ“šåº«**ï¼ˆTime-Series Database, TSDBï¼‰ã€‚ã€Mike èªªã€‚

## éˆæ„Ÿï¼šPrometheus çš„è¨­è¨ˆ

Sarah ç ”ç©¶äº†æ¥­ç•Œæœ€æµè¡Œçš„ç›£æ§ç³»çµ± Prometheusï¼Œç™¼ç¾å¹¾å€‹é—œéµè¨­è¨ˆï¼š

### 1. æŒ‡æ¨™æ ¼å¼

```
# Prometheus æŒ‡æ¨™æ ¼å¼
<metric_name>{<label>=<value>, ...} <value> <timestamp>

ç¯„ä¾‹ï¼š
http_requests_total{method="GET", status="200", path="/api/users"} 12456 1699776000
http_requests_total{method="POST", status="201", path="/api/orders"} 3421 1699776000
cpu_usage{host="web-server-01", core="0"} 78.5 1699776000
memory_usage{host="web-server-01", type="used"} 8589934592 1699776000
```

**é—œéµç‰¹æ€§ï¼š**
```
1. æŒ‡æ¨™åç¨±ï¼ˆmetric_nameï¼‰ï¼šæè¿°æ¸¬é‡ä»€éº¼
   - http_requests_totalï¼šHTTP è«‹æ±‚ç¸½æ•¸
   - cpu_usageï¼šCPU ä½¿ç”¨ç‡

2. æ¨™ç±¤ï¼ˆlabelsï¼‰ï¼šå¤šç¶­åº¦ç¯©é¸
   - method="GET"ï¼šæŒ‰ HTTP æ–¹æ³•ç¯©é¸
   - host="web-server-01"ï¼šæŒ‰ä¸»æ©Ÿç¯©é¸
   - å¯ä»¥ä»»æ„çµ„åˆæŸ¥è©¢

3. å€¼ï¼ˆvalueï¼‰ï¼šæ¸¬é‡å€¼

4. æ™‚é–“æˆ³ï¼ˆtimestampï¼‰ï¼šUnix æ™‚é–“æˆ³ï¼ˆç§’ï¼‰
```

### 2. Pull æ¨¡å‹ï¼ˆæ‹‰å–æ¨¡å‹ï¼‰

```
å‚³çµ±ï¼ˆPush æ¨¡å‹ï¼‰ï¼š
Agent â†’ æ¨é€ â†’ ç›£æ§ç³»çµ±

å•é¡Œï¼š
- Agent éœ€è¦çŸ¥é“ç›£æ§ç³»çµ±çš„åœ°å€
- ç›£æ§ç³»çµ±æ•…éšœæ™‚ï¼Œæ•¸æ“šä¸Ÿå¤±
- é›£ä»¥å‹•æ…‹æ“´å±•

Prometheusï¼ˆPull æ¨¡å‹ï¼‰ï¼š
Prometheus â†’ å®šæœŸæ‹‰å– â†’ Targetï¼ˆæ‡‰ç”¨ç¨‹åºï¼‰

å„ªå‹¢ï¼š
- Target ä¸éœ€è¦çŸ¥é“ Prometheus åœ°å€
- Prometheus å¯ä»¥ä¸»å‹•ç™¼ç¾ Target
- æ˜“æ–¼æª¢æ¸¬ Target æ˜¯å¦å­˜æ´»ï¼ˆæ‹‰å–å¤±æ•— = å®•æ©Ÿï¼‰
```

### 3. æœ¬åœ°å­˜å„² + å£“ç¸®

```
Prometheus çš„å­˜å„²å„ªåŒ–ï¼š
1. æ™‚é–“åˆ†å¡Šï¼ˆTime Blocksï¼‰
   - æ¯ 2 å°æ™‚çš„æ•¸æ“šä¸€å€‹ block
   - Block çµæ§‹ï¼š
     â”œâ”€â”€ chunks/ï¼ˆå£“ç¸®çš„æ™‚åºæ•¸æ“šï¼‰
     â”œâ”€â”€ indexï¼ˆå€’æ’ç´¢å¼•ï¼‰
     â””â”€â”€ meta.jsonï¼ˆå…ƒæ•¸æ“šï¼‰

2. é«˜æ•ˆå£“ç¸®ï¼ˆGorilla å£“ç¸®ç®—æ³•ï¼‰
   - Facebook é–‹ç™¼
   - é‡å°æ™‚åºæ•¸æ“šå„ªåŒ–
   - å£“ç¸®ç‡ï¼š10:1 åˆ° 20:1

3. ä¸‹æ¡æ¨£ï¼ˆDownsamplingï¼‰
   - ä¿ç•™åŸå§‹æ•¸æ“šï¼ˆ1 ç§’ç²¾åº¦ï¼‰ï¼šæœ€è¿‘ 7 å¤©
   - 5 åˆ†é˜èšåˆæ•¸æ“šï¼šæœ€è¿‘ 30 å¤©
   - 1 å°æ™‚èšåˆæ•¸æ“šï¼šæœ€è¿‘ 1 å¹´
```

Sarah èˆˆå¥®åœ°èªªï¼šã€Œé€™å°±æ˜¯æˆ‘éœ€è¦çš„ï¼ã€

## æ”¹é€²æ–¹æ¡ˆï¼šæ™‚åºæ•¸æ“šåº«ï¼ˆ2024/11/20ï¼‰

### æ ¸å¿ƒæ•¸æ“šçµæ§‹

```go
// Metric æŒ‡æ¨™
type Metric struct {
    Name      string            // æŒ‡æ¨™åç¨±
    Labels    map[string]string // æ¨™ç±¤
    Timestamp int64             // Unix æ™‚é–“æˆ³ï¼ˆæ¯«ç§’ï¼‰
    Value     float64           // å€¼
}

// ç¯„ä¾‹
metric := Metric{
    Name: "http_requests_total",
    Labels: map[string]string{
        "method": "GET",
        "status": "200",
        "path":   "/api/users",
    },
    Timestamp: time.Now().UnixMilli(),
    Value:     12456,
}
```

### å­˜å„²çµæ§‹ï¼šæŒ‰æ™‚é–“åˆ†ç‰‡

```go
// TimeSeries æ™‚é–“åºåˆ—
type TimeSeries struct {
    MetricName string
    Labels     map[string]string
    Points     []DataPoint
}

type DataPoint struct {
    Timestamp int64   // æ™‚é–“æˆ³ï¼ˆæ¯«ç§’ï¼‰
    Value     float64 // å€¼
}

// æŒ‰æ™‚é–“åˆ†ç‰‡å­˜å„²ï¼ˆæ¯å°æ™‚ä¸€å€‹æ–‡ä»¶ï¼‰
type TimeSeriesDB struct {
    blocks map[int64]*Block  // key: å°æ™‚çš„æ™‚é–“æˆ³
}

type Block struct {
    StartTime int64
    EndTime   int64
    Series    map[string]*TimeSeries  // key: metric_name + labels çš„çµ„åˆ
}
```

### å¯«å…¥æµç¨‹

```go
func (db *TimeSeriesDB) Write(metric Metric) error {
    // 1. è¨ˆç®—å±¬æ–¼å“ªå€‹ blockï¼ˆæŒ‰å°æ™‚ï¼‰
    blockTime := metric.Timestamp / (3600 * 1000) * (3600 * 1000)

    // 2. ç²å–æˆ–å‰µå»º block
    block := db.getOrCreateBlock(blockTime)

    // 3. ç”Ÿæˆ series keyï¼ˆmetric_name + labelsï¼‰
    seriesKey := generateSeriesKey(metric.Name, metric.Labels)

    // 4. ç²å–æˆ–å‰µå»º time series
    series := block.getSeries(seriesKey)
    if series == nil {
        series = &TimeSeries{
            MetricName: metric.Name,
            Labels:     metric.Labels,
            Points:     []DataPoint{},
        }
        block.putSeries(seriesKey, series)
    }

    // 5. è¿½åŠ æ•¸æ“šé»
    series.Points = append(series.Points, DataPoint{
        Timestamp: metric.Timestamp,
        Value:     metric.Value,
    })

    return nil
}

// ç”Ÿæˆ series key
func generateSeriesKey(name string, labels map[string]string) string {
    // ç¯„ä¾‹ï¼šhttp_requests_total{method="GET",status="200"}
    keys := make([]string, 0, len(labels))
    for k := range labels {
        keys = append(keys, k)
    }
    sort.Strings(keys)  // æ’åºä¿è­‰ä¸€è‡´æ€§

    var buf bytes.Buffer
    buf.WriteString(name)
    buf.WriteString("{")
    for i, k := range keys {
        if i > 0 {
            buf.WriteString(",")
        }
        buf.WriteString(k)
        buf.WriteString("=\"")
        buf.WriteString(labels[k])
        buf.WriteString("\"")
    }
    buf.WriteString("}")

    return buf.String()
}
```

### æŸ¥è©¢æµç¨‹

```go
// Query æŸ¥è©¢æŒ‡å®šæ™‚é–“ç¯„åœçš„æ•¸æ“š
func (db *TimeSeriesDB) Query(
    metricName string,
    labels map[string]string,
    startTime, endTime int64,
) ([]DataPoint, error) {

    results := []DataPoint{}

    // 1. æ‰¾åˆ°æ‰€æœ‰ç›¸é—œçš„ blocks
    blocks := db.getBlocksInRange(startTime, endTime)

    // 2. éæ­· blocks
    for _, block := range blocks {
        seriesKey := generateSeriesKey(metricName, labels)
        series := block.getSeries(seriesKey)
        if series == nil {
            continue
        }

        // 3. ç¯©é¸æ™‚é–“ç¯„åœå…§çš„æ•¸æ“šé»
        for _, point := range series.Points {
            if point.Timestamp >= startTime && point.Timestamp <= endTime {
                results = append(results, point)
            }
        }
    }

    // 4. æ’åºï¼ˆæŒ‰æ™‚é–“ï¼‰
    sort.Slice(results, func(i, j int) bool {
        return results[i].Timestamp < results[j].Timestamp
    })

    return results, nil
}
```

### èšåˆæŸ¥è©¢

```go
// Aggregate èšåˆæŸ¥è©¢ï¼ˆå¦‚ AVGã€MAXã€MINï¼‰
func (db *TimeSeriesDB) Aggregate(
    metricName string,
    labels map[string]string,
    startTime, endTime int64,
    aggFunc string,  // "avg", "max", "min", "sum", "p99"
) (float64, error) {

    // 1. æŸ¥è©¢åŸå§‹æ•¸æ“š
    points, err := db.Query(metricName, labels, startTime, endTime)
    if err != nil {
        return 0, err
    }

    if len(points) == 0 {
        return 0, nil
    }

    // 2. æ ¹æ“šèšåˆå‡½æ•¸è¨ˆç®—
    switch aggFunc {
    case "avg":
        sum := 0.0
        for _, p := range points {
            sum += p.Value
        }
        return sum / float64(len(points)), nil

    case "max":
        max := points[0].Value
        for _, p := range points {
            if p.Value > max {
                max = p.Value
            }
        }
        return max, nil

    case "min":
        min := points[0].Value
        for _, p := range points {
            if p.Value < min {
                min = p.Value
            }
        }
        return min, nil

    case "sum":
        sum := 0.0
        for _, p := range points {
            sum += p.Value
        }
        return sum, nil

    case "p99":
        // P99 ç™¾åˆ†ä½æ•¸
        values := make([]float64, len(points))
        for i, p := range points {
            values[i] = p.Value
        }
        sort.Float64s(values)
        index := int(float64(len(values)) * 0.99)
        return values[index], nil

    default:
        return 0, fmt.Errorf("unknown aggregation function: %s", aggFunc)
    }
}
```

### æ€§èƒ½å°æ¯”ï¼ˆ2024/11/22 æ¸¬è©¦ï¼‰

```
å ´æ™¯ï¼šæŸ¥è©¢éå» 1 å°æ™‚çš„å¹³å‡ CPU

æ–¹æ¡ˆ Aï¼šPostgreSQL
- æŸ¥è©¢æ™‚é–“ï¼š8.7 ç§’
- æƒæè¨˜éŒ„ï¼š720,000 æ¢
- å­˜å„²å¤§å°ï¼š72 MBï¼ˆæœªå£“ç¸®ï¼‰

æ–¹æ¡ˆ Bï¼šæ™‚åºæ•¸æ“šåº«
- æŸ¥è©¢æ™‚é–“ï¼š0.05 ç§’ âœ…
- æƒæè¨˜éŒ„ï¼š3,600 å€‹æ•¸æ“šé»ï¼ˆå·²æŒ‰ block çµ„ç¹”ï¼‰
- å­˜å„²å¤§å°ï¼šç´„ 5 MBï¼ˆå£“ç¸®ï¼‰

æå‡ï¼š
- æŸ¥è©¢é€Ÿåº¦ï¼š174 å€
- å­˜å„²ï¼šç¯€çœ 93%
```

## ç¬¬ä¸‰æ¬¡ç½é›£ï¼šå­˜å„²æˆæœ¬çˆ†ç‚¸ï¼ˆ2024/11/25ï¼‰

### èƒŒæ™¯ï¼šç›£æ§ç¯„åœæ“´å¤§

ç”¢å“ç¶“ç†ï¼šã€Œæˆ‘å€‘è¦ç›£æ§æ‰€æœ‰æœå‹™ï¼ã€

æ–°å¢ç›£æ§ï¼š
- Web æœå‹™å™¨ï¼š20 å° â†’ 100 å°
- è³‡æ–™åº«ï¼š5 å° â†’ 20 å°
- Redisï¼š10 å° â†’ 50 å°
- æ¯å°æ–°å¢æ›´å¤šæŒ‡æ¨™ï¼ˆ50 å€‹ â†’ 200 å€‹ï¼‰

**æ•¸æ“šé‡è¨ˆç®—ï¼š**
```
ä¹‹å‰ï¼š
- 20 å° Ã— 10 æŒ‡æ¨™ = 200 å€‹æ™‚é–“åºåˆ—
- æ¯ç§’ 200 å€‹æ•¸æ“šé»
- æ¯å¤©ï¼š200 Ã— 86,400 = 17,280,000 å€‹æ•¸æ“šé»

ç¾åœ¨ï¼š
- 170 å° Ã— 200 æŒ‡æ¨™ = 34,000 å€‹æ™‚é–“åºåˆ—
- æ¯ç§’ 34,000 å€‹æ•¸æ“šé»
- æ¯å¤©ï¼š34,000 Ã— 86,400 = 2,937,600,000 å€‹æ•¸æ“šé»ï¼ˆ29.4 å„„ï¼‰

å­˜å„²ï¼ˆä¿ç•™ 30 å¤©ï¼‰ï¼š
- æ¯å€‹æ•¸æ“šé»ï¼š16 bytesï¼ˆ8 bytes timestamp + 8 bytes valueï¼‰
- 30 å¤©ï¼š29.4 å„„ Ã— 30 Ã— 16 bytes = 1.41 TB âŒ

æˆæœ¬ï¼ˆAWS EBSï¼‰ï¼š
- 1.41 TB Ã— $0.1/GB/æœˆ = $144/æœˆ
- ä¸€å¹´ï¼š$1,728
```

Sarah æ“”å¿ƒï¼šã€Œæˆæœ¬å¤ªé«˜äº†ï¼Œè€Œä¸”é‚„åœ¨å¢é•·...ã€

### è§£æ±ºæ–¹æ¡ˆ 1ï¼šå£“ç¸®ç®—æ³•ï¼ˆGorillaï¼‰

**Gorilla å£“ç¸®ç®—æ³•**ï¼ˆFacebook 2015ï¼‰ï¼š

```
åŸç†ï¼šæ™‚åºæ•¸æ“šçš„ç‰¹é»
1. æ™‚é–“æˆ³è¦å¾‹ï¼šé€šå¸¸æ˜¯å›ºå®šé–“éš”ï¼ˆå¦‚æ¯ç§’ä¸€å€‹ï¼‰
2. å€¼è®ŠåŒ–å°ï¼šç›¸é„°æ•¸æ“šé»çš„å€¼ç›¸è¿‘ï¼ˆå¦‚ CPU 78% â†’ 79%ï¼‰

å£“ç¸®æŠ€è¡“ï¼š
1. Delta-of-Delta ç·¨ç¢¼ï¼ˆæ™‚é–“æˆ³ï¼‰
   åŸå§‹ï¼š1000, 1001, 1002, 1003
   Deltaï¼š   1,    1,    1,    1
   Delta-of-Delta: 0, 0, 0ï¼ˆå…¨æ˜¯ 0ï¼ï¼‰
   â†’ ç”¨ 1 bit è¡¨ç¤ºã€Œèˆ‡ä¸Šæ¬¡ç›¸åŒã€

2. XOR ç·¨ç¢¼ï¼ˆå€¼ï¼‰
   åŸå§‹ï¼š78.5, 78.7, 78.3
   äºŒé€²åˆ¶ XORï¼šåªè¨˜éŒ„è®ŠåŒ–çš„ä½
   â†’ ç”¨å¯è®Šé•·åº¦ç·¨ç¢¼

å£“ç¸®ç‡ï¼š
- åŸå§‹ï¼š16 bytes/é»
- å£“ç¸®å¾Œï¼šç´„ 1.37 bytes/é»
- å£“ç¸®ç‡ï¼š11.7:1 âœ…
```

**å¯¦ç¾ï¼ˆç°¡åŒ–ç‰ˆï¼‰ï¼š**

```go
type GorillaSeries struct {
    baseTimestamp int64   // åŸºæº–æ™‚é–“æˆ³
    baseValue     uint64  // åŸºæº–å€¼ï¼ˆfloat64 è½‰ç‚º uint64ï¼‰

    timestamps []byte  // å£“ç¸®çš„æ™‚é–“æˆ³
    values     []byte  // å£“ç¸®çš„å€¼
}

// è¿½åŠ æ•¸æ“šé»ï¼ˆDelta-of-Deltaï¼‰
func (s *GorillaSeries) Append(timestamp int64, value float64) {
    // æ™‚é–“æˆ³ï¼šDelta-of-Delta ç·¨ç¢¼
    if s.baseTimestamp == 0 {
        s.baseTimestamp = timestamp
    } else {
        // è¨ˆç®— delta
        delta := timestamp - s.baseTimestamp
        // ... å¯«å…¥å¯è®Šé•·åº¦ç·¨ç¢¼
    }

    // å€¼ï¼šXOR ç·¨ç¢¼
    valueUint := math.Float64bits(value)
    if s.baseValue == 0 {
        s.baseValue = valueUint
    } else {
        // XOR èˆ‡å‰ä¸€å€‹å€¼
        xor := valueUint ^ s.baseValue
        // ... å¯«å…¥å¯è®Šé•·åº¦ç·¨ç¢¼
    }

    s.baseValue = valueUint
}
```

**æ•ˆæœï¼š**
```
å£“ç¸®å‰ï¼š1.41 TB
å£“ç¸®å¾Œï¼š1.41 TB Ã· 11.7 = 120.5 GB âœ…

æˆæœ¬ï¼š
- 120.5 GB Ã— $0.1/GB/æœˆ = $12/æœˆ
- ä¸€å¹´ï¼š$144

ç¯€çœï¼š$1,728 - $144 = $1,584/å¹´
```

### è§£æ±ºæ–¹æ¡ˆ 2ï¼šä¸‹æ¡æ¨£ï¼ˆDownsamplingï¼‰

ã€ŒèˆŠæ•¸æ“šä¸éœ€è¦é‚£éº¼ç²¾ç¢ºï¼ã€Sarah æƒ³ã€‚

**ç­–ç•¥ï¼š**
```
æ•¸æ“šä¿ç•™ç­–ç•¥ï¼š
- åŸå§‹æ•¸æ“šï¼ˆ1 ç§’ç²¾åº¦ï¼‰ï¼šä¿ç•™ 7 å¤©
- 5 åˆ†é˜èšåˆæ•¸æ“šï¼šä¿ç•™ 30 å¤©
- 1 å°æ™‚èšåˆæ•¸æ“šï¼šä¿ç•™ 1 å¹´

ç¯„ä¾‹ï¼š
åŸå§‹æ•¸æ“šï¼ˆ1 ç§’ï¼‰ï¼š
00:00:00 - CPU: 78%
00:00:01 - CPU: 79%
00:00:02 - CPU: 77%
...
00:04:59 - CPU: 80%

5 åˆ†é˜èšåˆï¼š
00:00:00 - CPU: avg=78.5%, max=82%, min=75%, p99=81%

å„ªå‹¢ï¼š
- 1 å€‹èšåˆæ•¸æ“šé» = 300 å€‹åŸå§‹æ•¸æ“šé»
- å­˜å„²æ¸›å°‘ 75 å€ï¼ˆä¿ç•™ avgã€maxã€minã€p99ï¼‰
```

**å¯¦ç¾ï¼š**

```go
type Aggregation struct {
    Avg float64
    Max float64
    Min float64
    P99 float64
}

// Downsample ä¸‹æ¡æ¨£
func (db *TimeSeriesDB) Downsample(
    metricName string,
    labels map[string]string,
    startTime, endTime int64,
    interval int64,  // èšåˆé–“éš”ï¼ˆå¦‚ 5 åˆ†é˜ = 300,000 æ¯«ç§’ï¼‰
) ([]Aggregation, error) {

    results := []Aggregation{}

    // å°‡æ™‚é–“ç¯„åœåˆ†å‰²ç‚ºå¤šå€‹ interval
    for t := startTime; t < endTime; t += interval {
        // æŸ¥è©¢è©² interval çš„åŸå§‹æ•¸æ“š
        points, _ := db.Query(metricName, labels, t, t+interval)

        if len(points) == 0 {
            continue
        }

        // è¨ˆç®—èšåˆ
        agg := Aggregation{}

        // Avg
        sum := 0.0
        for _, p := range points {
            sum += p.Value
        }
        agg.Avg = sum / float64(len(points))

        // Max & Min
        agg.Max = points[0].Value
        agg.Min = points[0].Value
        for _, p := range points {
            if p.Value > agg.Max {
                agg.Max = p.Value
            }
            if p.Value < agg.Min {
                agg.Min = p.Value
            }
        }

        // P99
        values := make([]float64, len(points))
        for i, p := range points {
            values[i] = p.Value
        }
        sort.Float64s(values)
        p99Index := int(float64(len(values)) * 0.99)
        agg.P99 = values[p99Index]

        results = append(results, agg)
    }

    return results, nil
}

// å®šæœŸä¸‹æ¡æ¨£ä»»å‹™
func (db *TimeSeriesDB) StartDownsamplingTask() {
    ticker := time.NewTicker(1 * time.Hour)
    for range ticker.C {
        // å°‡ 7 å¤©å‰çš„åŸå§‹æ•¸æ“šä¸‹æ¡æ¨£ç‚º 5 åˆ†é˜èšåˆ
        sevenDaysAgo := time.Now().Add(-7 * 24 * time.Hour).UnixMilli()

        // ... éæ­·æ‰€æœ‰æ™‚é–“åºåˆ—ï¼Œä¸‹æ¡æ¨£ä¸¦åˆªé™¤åŸå§‹æ•¸æ“š
    }
}
```

**å­˜å„²å°æ¯”ï¼š**
```
å ´æ™¯ï¼šä¿ç•™ 30 å¤©æ•¸æ“š

æ–¹æ¡ˆ Aï¼šå…¨éƒ¨åŸå§‹æ•¸æ“šï¼ˆ1 ç§’ç²¾åº¦ï¼‰
- æ•¸æ“šé»ï¼š29.4 å„„ Ã— 30 = 882 å„„
- å£“ç¸®å¾Œï¼š120.5 GB Ã— 30 = 3.6 TB âŒ

æ–¹æ¡ˆ Bï¼šåˆ†å±¤å­˜å„²
- æœ€è¿‘ 7 å¤©ï¼ˆ1 ç§’ç²¾åº¦ï¼‰ï¼š120.5 GB Ã— 7 = 843 GB
- 7-30 å¤©ï¼ˆ5 åˆ†é˜èšåˆï¼‰ï¼š120.5 GB Ã— 23 Ã· 300 = 9.2 GB
- ç¸½è¨ˆï¼š852.2 GB âœ…

ç¯€çœï¼š3.6 TB - 852 GB = 2.76 TBï¼ˆ76% æ¸›å°‘ï¼‰
```

## ç¬¬å››æ¬¡æŒ‘æˆ°ï¼šå‘Šè­¦å»¶é²ï¼ˆ2024/12/01ï¼‰

### å•é¡Œï¼šè¢«å‹•ç›£æ§

ç›®å‰çš„ç³»çµ±ï¼š
```
1. æ”¶é›†æŒ‡æ¨™ â†’ å­˜å…¥æ™‚åºæ•¸æ“šåº«
2. ç”¨æˆ¶æ‰“é–‹ Grafana å„€è¡¨æ¿ â†’ æŸ¥çœ‹æŒ‡æ¨™
3. ç”¨æˆ¶ç™¼ç¾å•é¡Œ â†’ æ‰‹å‹•è™•ç†

å•é¡Œï¼š
- éœ€è¦äººç›¯è‘—å„€è¡¨æ¿ï¼ˆä¸ç¾å¯¦ï¼‰
- å•é¡Œç™¼ç”Ÿåˆ°ç™¼ç¾ï¼šå»¶é²æ•¸åˆ†é˜åˆ°æ•¸å°æ™‚
- ç„¡æ³•åŠæ™‚éŸ¿æ‡‰
```

ç”¢å“ç¶“ç†ï¼šã€Œæˆ‘å€‘éœ€è¦**å‘Šè­¦ç³»çµ±**ï¼CPU > 80% è‡ªå‹•ç™¼é€é€šçŸ¥ï¼ã€

### å‘Šè­¦è¦å‰‡å¼•æ“

```go
// AlertRule å‘Šè­¦è¦å‰‡
type AlertRule struct {
    Name        string            // è¦å‰‡åç¨±
    MetricName  string            // ç›£æ§çš„æŒ‡æ¨™
    Labels      map[string]string // æ¨™ç±¤ç¯©é¸
    Condition   string            // æ¢ä»¶ï¼ˆå¦‚ ">", "<", "=="ï¼‰
    Threshold   float64           // é–¾å€¼
    Duration    time.Duration     // æŒçºŒæ™‚é–“ï¼ˆé€£çºŒæ»¿è¶³å¤šä¹…æ‰å‘Šè­¦ï¼‰
    Severity    string            // åš´é‡ç´šåˆ¥ï¼ˆcritical, warning, infoï¼‰
    Message     string            // å‘Šè­¦æ¶ˆæ¯æ¨¡æ¿
}

// ç¯„ä¾‹ï¼šCPU ä½¿ç”¨ç‡å‘Šè­¦
rule := AlertRule{
    Name:       "HighCPUUsage",
    MetricName: "cpu_usage",
    Labels: map[string]string{
        "host": "web-server-*",  // æ‰€æœ‰ web æœå‹™å™¨
    },
    Condition:  ">",
    Threshold:  80.0,
    Duration:   5 * time.Minute,  // æŒçºŒ 5 åˆ†é˜
    Severity:   "critical",
    Message:    "ä¸»æ©Ÿ {{.Host}} CPU ä½¿ç”¨ç‡ {{.Value}}% è¶…é 80%",
}
```

### å‘Šè­¦è©•ä¼°å™¨

```go
type AlertEvaluator struct {
    db    *TimeSeriesDB
    rules []*AlertRule

    // è¨˜éŒ„è¦å‰‡çš„è§¸ç™¼ç‹€æ…‹
    ruleStates map[string]*RuleState
}

type RuleState struct {
    FirstTriggeredAt time.Time  // é¦–æ¬¡è§¸ç™¼æ™‚é–“
    TriggeredCount   int         // è§¸ç™¼æ¬¡æ•¸
    Firing           bool        // æ˜¯å¦æ­£åœ¨å‘Šè­¦
}

// Evaluate è©•ä¼°æ‰€æœ‰å‘Šè­¦è¦å‰‡
func (ae *AlertEvaluator) Evaluate() {
    for _, rule := range ae.rules {
        ae.evaluateRule(rule)
    }
}

func (ae *AlertEvaluator) evaluateRule(rule *AlertRule) {
    // 1. æŸ¥è©¢æœ€è¿‘çš„æ•¸æ“š
    now := time.Now().UnixMilli()
    points, _ := ae.db.Query(
        rule.MetricName,
        rule.Labels,
        now - int64(rule.Duration.Milliseconds()),
        now,
    )

    if len(points) == 0 {
        return
    }

    // 2. æª¢æŸ¥æ‰€æœ‰æ•¸æ“šé»æ˜¯å¦æ»¿è¶³æ¢ä»¶
    allMatch := true
    for _, point := range points {
        if !ae.checkCondition(point.Value, rule.Condition, rule.Threshold) {
            allMatch = false
            break
        }
    }

    // 3. æ›´æ–°è¦å‰‡ç‹€æ…‹
    state := ae.getRuleState(rule.Name)

    if allMatch {
        // æ»¿è¶³æ¢ä»¶
        if state.FirstTriggeredAt.IsZero() {
            state.FirstTriggeredAt = time.Now()
        }
        state.TriggeredCount++

        // æª¢æŸ¥æ˜¯å¦æŒçºŒè¶³å¤ ä¹…
        if time.Since(state.FirstTriggeredAt) >= rule.Duration {
            if !state.Firing {
                // é¦–æ¬¡è§¸ç™¼å‘Šè­¦
                ae.fireAlert(rule, points[len(points)-1].Value)
                state.Firing = true
            }
        }
    } else {
        // ä¸æ»¿è¶³æ¢ä»¶ï¼Œé‡ç½®ç‹€æ…‹
        if state.Firing {
            // å‘Šè­¦è§£é™¤
            ae.resolveAlert(rule)
        }
        state.FirstTriggeredAt = time.Time{}
        state.TriggeredCount = 0
        state.Firing = false
    }
}

// checkCondition æª¢æŸ¥æ¢ä»¶
func (ae *AlertEvaluator) checkCondition(value float64, condition string, threshold float64) bool {
    switch condition {
    case ">":
        return value > threshold
    case ">=":
        return value >= threshold
    case "<":
        return value < threshold
    case "<=":
        return value <= threshold
    case "==":
        return value == threshold
    case "!=":
        return value != threshold
    default:
        return false
    }
}

// fireAlert è§¸ç™¼å‘Šè­¦
func (ae *AlertEvaluator) fireAlert(rule *AlertRule, value float64) {
    // æ¸²æŸ“å‘Šè­¦æ¶ˆæ¯
    message := ae.renderMessage(rule.Message, map[string]interface{}{
        "Value": value,
        "Threshold": rule.Threshold,
    })

    // ç™¼é€é€šçŸ¥ï¼ˆéƒµä»¶ã€Slackã€SMS ç­‰ï¼‰
    ae.sendNotification(rule.Severity, message)

    log.Printf("[ALERT] %s: %s", rule.Name, message)
}

// resolveAlert è§£é™¤å‘Šè­¦
func (ae *AlertEvaluator) resolveAlert(rule *AlertRule) {
    message := fmt.Sprintf("å‘Šè­¦ %s å·²è§£é™¤", rule.Name)
    ae.sendNotification("info", message)

    log.Printf("[RESOLVED] %s", rule.Name)
}

// sendNotification ç™¼é€é€šçŸ¥
func (ae *AlertEvaluator) sendNotification(severity, message string) {
    // æ ¹æ“šåš´é‡ç´šåˆ¥é¸æ“‡é€šçŸ¥æ¸ é“
    switch severity {
    case "critical":
        // é›»è©± + SMS + Slack + éƒµä»¶
        sendSMS(message)
        sendSlack(message)
        sendEmail(message)
    case "warning":
        // Slack + éƒµä»¶
        sendSlack(message)
        sendEmail(message)
    case "info":
        // éƒµä»¶
        sendEmail(message)
    }
}
```

### å®šæœŸè©•ä¼°

```go
func (ae *AlertEvaluator) Start() {
    ticker := time.NewTicker(30 * time.Second)  // æ¯ 30 ç§’è©•ä¼°ä¸€æ¬¡
    for range ticker.C {
        ae.Evaluate()
    }
}
```

### å‘Šè­¦ç¤ºä¾‹

**é…ç½®ï¼š**
```yaml
# alerts.yml
rules:
  - name: HighCPUUsage
    metric: cpu_usage
    condition: ">"
    threshold: 80
    duration: 5m
    severity: critical
    message: "ä¸»æ©Ÿ {{.Host}} CPU ä½¿ç”¨ç‡ {{.Value}}% æŒçºŒè¶…é 80%"

  - name: HighMemoryUsage
    metric: memory_usage
    condition: ">"
    threshold: 85
    duration: 10m
    severity: warning
    message: "ä¸»æ©Ÿ {{.Host}} å…§å­˜ä½¿ç”¨ç‡ {{.Value}}% è¶…é 85%"

  - name: HighErrorRate
    metric: http_errors_rate
    condition: ">"
    threshold: 5
    duration: 1m
    severity: critical
    message: "HTTP éŒ¯èª¤ç‡ {{.Value}}% è¶…é 5%"
```

**è§¸ç™¼æµç¨‹ï¼š**
```
æ™‚é–“ç·šï¼šCPU å‘Šè­¦

14:00:00 - CPU: 82%ï¼ˆè¶…é 80%ï¼Œé–‹å§‹è¨ˆæ™‚ï¼‰
14:01:00 - CPU: 83%ï¼ˆæŒçºŒ 1 åˆ†é˜ï¼‰
14:02:00 - CPU: 85%ï¼ˆæŒçºŒ 2 åˆ†é˜ï¼‰
14:03:00 - CPU: 84%ï¼ˆæŒçºŒ 3 åˆ†é˜ï¼‰
14:04:00 - CPU: 86%ï¼ˆæŒçºŒ 4 åˆ†é˜ï¼‰
14:05:00 - CPU: 87%ï¼ˆæŒçºŒ 5 åˆ†é˜ â†’ è§¸ç™¼å‘Šè­¦ï¼ğŸ“§ï¼‰

14:10:00 - CPU: 75%ï¼ˆä½æ–¼ 80% â†’ å‘Šè­¦è§£é™¤ âœ…ï¼‰
```

## ç¬¬äº”æ¬¡å„ªåŒ–ï¼šæŸ¥è©¢èªè¨€ï¼ˆPromQLï¼‰ï¼ˆ2024/12/05ï¼‰

### å•é¡Œï¼šè¤‡é›œæŸ¥è©¢å›°é›£

ç”¢å“ç¶“ç†çš„éœ€æ±‚è¶Šä¾†è¶Šè¤‡é›œï¼š

```
éœ€æ±‚ 1ï¼šéå» 5 åˆ†é˜ï¼Œæ‰€æœ‰ Web æœå‹™å™¨çš„å¹³å‡ CPU
éœ€æ±‚ 2ï¼šHTTP éŒ¯èª¤ç‡ï¼ˆerrors / total Ã— 100%ï¼‰
éœ€æ±‚ 3ï¼šP99 éŸ¿æ‡‰æ™‚é–“ï¼ˆæŒ‰è·¯å¾‘åˆ†çµ„ï¼‰
éœ€æ±‚ 4ï¼šQPS å¢é•·ç‡ï¼ˆèˆ‡ 1 å°æ™‚å‰å°æ¯”ï¼‰
```

ç”¨ä»£ç¢¼å¯¦ç¾å¤ªéº»ç…©ï¼

### è§£æ±ºæ–¹æ¡ˆï¼šæŸ¥è©¢èªè¨€ï¼ˆåƒè€ƒ PromQLï¼‰

**åŸºæœ¬æŸ¥è©¢ï¼š**
```promql
# æŸ¥è©¢æŒ‡æ¨™
cpu_usage{host="web-server-01"}

# æ™‚é–“ç¯„åœ
cpu_usage{host="web-server-01"}[5m]

# èšåˆå‡½æ•¸
avg(cpu_usage{host=~"web-server-.*"})
max(cpu_usage{host=~"web-server-.*"})
min(cpu_usage{host=~"web-server-.*"})

# æŒ‰æ¨™ç±¤åˆ†çµ„
avg by (host) (cpu_usage)
```

**è¤‡é›œæŸ¥è©¢ï¼š**
```promql
# HTTP éŒ¯èª¤ç‡
sum(http_requests_total{status=~"5.."}) / sum(http_requests_total) * 100

# QPSï¼ˆæ¯ç§’è«‹æ±‚æ•¸ï¼‰
rate(http_requests_total[1m])

# P99 éŸ¿æ‡‰æ™‚é–“ï¼ˆæŒ‰è·¯å¾‘åˆ†çµ„ï¼‰
histogram_quantile(0.99, http_request_duration_bucket) by (path)

# CPU å¢é•·ç‡ï¼ˆèˆ‡ 1 å°æ™‚å‰å°æ¯”ï¼‰
(cpu_usage - cpu_usage offset 1h) / cpu_usage offset 1h * 100
```

**å¯¦ç¾ï¼ˆç°¡åŒ–ç‰ˆï¼‰ï¼š**

```go
// QueryEngine æŸ¥è©¢å¼•æ“
type QueryEngine struct {
    db *TimeSeriesDB
}

// Execute åŸ·è¡ŒæŸ¥è©¢
func (qe *QueryEngine) Execute(query string) ([]DataPoint, error) {
    // è§£ææŸ¥è©¢èªå¥
    ast, err := parseQuery(query)
    if err != nil {
        return nil, err
    }

    // åŸ·è¡ŒæŸ¥è©¢
    return qe.executeAST(ast)
}

// ç¯„ä¾‹ï¼šavg(cpu_usage{host="web-server-01"}[5m])
func (qe *QueryEngine) executeAST(ast *AST) ([]DataPoint, error) {
    switch ast.Type {
    case "metric":
        // æŸ¥è©¢æŒ‡æ¨™
        return qe.db.Query(ast.MetricName, ast.Labels, ast.StartTime, ast.EndTime)

    case "avg":
        // èšåˆï¼šå¹³å‡å€¼
        points, _ := qe.executeAST(ast.Children[0])
        avg, _ := calculateAvg(points)
        return []DataPoint{{Value: avg}}, nil

    case "rate":
        // é€Ÿç‡ï¼š(last - first) / time_range
        points, _ := qe.executeAST(ast.Children[0])
        if len(points) < 2 {
            return nil, nil
        }
        first := points[0]
        last := points[len(points)-1]
        timeRange := (last.Timestamp - first.Timestamp) / 1000.0  // ç§’
        rate := (last.Value - first.Value) / timeRange
        return []DataPoint{{Value: rate}}, nil

    // ... å…¶ä»–å‡½æ•¸
    }

    return nil, fmt.Errorf("unknown AST type: %s", ast.Type)
}
```

## æ–°çš„æŒ‘æˆ°ï¼šåˆ†å¸ƒå¼æ“´å±•

### ç•¶å‰æ¶æ§‹ç“¶é ¸

```
å–®æ©Ÿæ™‚åºæ•¸æ“šåº«å®¹é‡ï¼š
- æ™‚é–“åºåˆ—æ•¸ï¼šç´„ 100 è¬
- æ¯ç§’å¯«å…¥ï¼šç´„ 10 è¬å€‹æ•¸æ“šé»
- å­˜å„²ï¼šç´„ 1 TBï¼ˆå£“ç¸®å¾Œï¼‰
- æŸ¥è©¢ QPSï¼šç´„ 1,000

å•é¡Œï¼š
- ç„¡æ³•æ©«å‘æ“´å±•
- å–®é»æ•…éšœ
- å­˜å„²æœ‰é™
```

### 10x æ“´å±•ï¼šåˆ†ç‰‡ + å‰¯æœ¬

```
æ¶æ§‹è®ŠåŒ–ï¼š

ç•¶å‰ï¼ˆå–®æ©Ÿï¼‰ï¼š
Prometheus â†’ TSDB (æœ¬åœ°å­˜å„²)

å„ªåŒ–å¾Œï¼ˆåˆ†ç‰‡ï¼‰ï¼š
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Prometheus  â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Write Proxy  â”‚ï¼ˆæŒ‰ hash åˆ†ç‰‡ï¼‰
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â†“           â†“           â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
   â”‚TSDB 1 â”‚   â”‚TSDB 2 â”‚   â”‚TSDB 3 â”‚
   â”‚(ä¸»)   â”‚   â”‚(ä¸»)   â”‚   â”‚(ä¸»)   â”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
       â†“           â†“           â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
   â”‚TSDB 1'â”‚   â”‚TSDB 2'â”‚   â”‚TSDB 3'â”‚
   â”‚(å‰¯æœ¬) â”‚   â”‚(å‰¯æœ¬) â”‚   â”‚(å‰¯æœ¬) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜

åˆ†ç‰‡ç­–ç•¥ï¼š
- æŒ‰æ™‚é–“åºåˆ— hash åˆ†ç‰‡
- hash(metric_name + labels) % 3

æŸ¥è©¢ï¼š
- ä¸¦è¡ŒæŸ¥è©¢æ‰€æœ‰åˆ†ç‰‡
- åˆä½µçµæœ

å®¹é‡ï¼š
- 3 å€‹åˆ†ç‰‡ Ã— 100 è¬åºåˆ— = 300 è¬åºåˆ—
- 3 å€‹åˆ†ç‰‡ Ã— 10 è¬ å¯«å…¥/ç§’ = 30 è¬ å¯«å…¥/ç§’
```

### 100x æ“´å±•ï¼šå°ˆæ¥­ TSDBï¼ˆå¦‚ VictoriaMetricsã€Thanosï¼‰

```
æ¶æ§‹ï¼š

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Prometheus  â”‚ï¼ˆå¤šå€‹å¯¦ä¾‹ï¼‰
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Thanos    â”‚
            â”‚   (æŸ¥è©¢å±¤)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â†“           â†“               â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ TSDB  â”‚   â”‚ TSDB  â”‚   â”‚  S3      â”‚
   â”‚ (çŸ­æœŸ)â”‚   â”‚ (çŸ­æœŸ)â”‚   â”‚ (é•·æœŸ)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹æ€§ï¼š
1. é•·æœŸå­˜å„²ï¼šå°‡èˆŠæ•¸æ“šå£“ç¸®å¾Œå­˜å…¥ S3ï¼ˆä¾¿å®œï¼‰
2. å…¨å±€æŸ¥è©¢ï¼šè·¨å¤šå€‹ Prometheus å¯¦ä¾‹æŸ¥è©¢
3. ä¸‹æ¡æ¨£ï¼šè‡ªå‹•å°‡èˆŠæ•¸æ“šé™æ¡æ¨£
4. å»é‡ï¼šå¤šå€‹å‰¯æœ¬çš„æ•¸æ“šè‡ªå‹•å»é‡

å®¹é‡ï¼š
- æ”¯æŒæ•¸åƒè¬æ™‚é–“åºåˆ—
- æ¯ç§’æ•¸ç™¾è¬æ•¸æ“šé»
- PB ç´šå­˜å„²ï¼ˆS3ï¼‰
```

## çœŸå¯¦æ¡ˆä¾‹ï¼šUber çš„ç›£æ§ç³»çµ±æ¼”é€²

### Uber M3 çš„èª•ç”Ÿ

**2014 å¹´ï¼ˆä½¿ç”¨ Graphiteï¼‰ï¼š**
```
å•é¡Œï¼š
- å¯«å…¥æ€§èƒ½å·®ï¼ˆæ¯ç§’ 10 è¬æŒ‡æ¨™ï¼‰
- æŸ¥è©¢æ…¢ï¼ˆèšåˆéœ€è¦ 30 ç§’+ï¼‰
- å­˜å„²æ˜‚è²´ï¼ˆæœªå£“ç¸®ï¼‰
- ç„¡æ³•æ“´å±•
```

**2016 å¹´ï¼ˆé–‹ç™¼ M3ï¼‰ï¼š**
```
M3 è¨­è¨ˆï¼š
1. M3DBï¼šåˆ†å¸ƒå¼æ™‚åºæ•¸æ“šåº«
   - ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡
   - è¤‡è£½ä¿‚æ•¸ 3ï¼ˆé«˜å¯ç”¨ï¼‰
   - è‡ªå®šç¾©å£“ç¸®ï¼ˆ20:1ï¼‰

2. M3 Coordinatorï¼šæŸ¥è©¢å”èª¿å™¨
   - ä¸¦è¡ŒæŸ¥è©¢æ‰€æœ‰åˆ†ç‰‡
   - åˆä½µçµæœ
   - æŸ¥è©¢ç·©å­˜

3. M3 Aggregatorï¼šå¯¦æ™‚èšåˆ
   - åœ¨å¯«å…¥æ™‚é èšåˆï¼ˆå¦‚ 1 åˆ†é˜å¹³å‡ï¼‰
   - æ¸›å°‘å­˜å„²å’ŒæŸ¥è©¢å£“åŠ›
```

**2020 å¹´ï¼ˆM3 é–‹æºï¼‰ï¼š**
```
è¦æ¨¡ï¼š
- æ™‚é–“åºåˆ—ï¼š6.5 å„„+
- å¯«å…¥ï¼šæ¯ç§’ 1,000 è¬+ æ•¸æ“šé»
- å­˜å„²ï¼š60+ PB
- æŸ¥è©¢ï¼šæ¯ç§’ 20 è¬+ æŸ¥è©¢

æ€§èƒ½ï¼š
- å¯«å…¥å»¶é²ï¼šP99 < 10ms
- æŸ¥è©¢å»¶é²ï¼šP99 < 100ms
- å£“ç¸®ç‡ï¼š20:1
```

åƒè€ƒè³‡æ–™ï¼š
- [Uber M3: é–‹æºåˆ†å¸ƒå¼æ™‚åºæ•¸æ“šåº«](https://eng.uber.com/m3/)
- [M3 GitHub](https://github.com/m3db/m3)

## ç¸½çµèˆ‡å°æ¯”

### æ ¸å¿ƒè¨­è¨ˆåŸå‰‡

```
1. æ™‚åºæ•¸æ“šåº«ï¼ˆTSDBï¼‰
   å•é¡Œï¼šPostgreSQL æŸ¥è©¢æ…¢ï¼ˆ8.7 ç§’ï¼‰
   æ–¹æ¡ˆï¼šå°ˆé–€çš„æ™‚åºå­˜å„²ï¼ˆæŒ‰æ™‚é–“åˆ†å¡Šï¼‰
   æ•ˆæœï¼š0.05 ç§’ï¼ˆæå‡ 174 å€ï¼‰

2. å£“ç¸®ç®—æ³•ï¼ˆGorillaï¼‰
   å•é¡Œï¼šå­˜å„²æˆæœ¬é«˜ï¼ˆ1.41 TBï¼‰
   æ–¹æ¡ˆï¼šDelta-of-Delta + XOR ç·¨ç¢¼
   æ•ˆæœï¼š120 GBï¼ˆå£“ç¸®ç‡ 11.7:1ï¼‰

3. ä¸‹æ¡æ¨£ï¼ˆDownsamplingï¼‰
   å•é¡Œï¼šé•·æœŸå­˜å„²æˆæœ¬ï¼ˆ3.6 TB/æœˆï¼‰
   æ–¹æ¡ˆï¼šåˆ†å±¤å­˜å„²ï¼ˆ7 å¤©åŸå§‹ + èšåˆï¼‰
   æ•ˆæœï¼š852 GBï¼ˆç¯€çœ 76%ï¼‰

4. å‘Šè­¦è¦å‰‡å¼•æ“
   å•é¡Œï¼šè¢«å‹•ç›£æ§ï¼ˆäººå·¥æŸ¥çœ‹ï¼‰
   æ–¹æ¡ˆï¼šè‡ªå‹•è©•ä¼° + é€šçŸ¥
   æ•ˆæœï¼šç§’ç´šç™¼ç¾å•é¡Œ

5. æŸ¥è©¢èªè¨€ï¼ˆPromQLï¼‰
   å•é¡Œï¼šè¤‡é›œæŸ¥è©¢å›°é›£
   æ–¹æ¡ˆï¼šè²æ˜å¼æŸ¥è©¢èªè¨€
   æ•ˆæœï¼šéˆæ´»å¼·å¤§
```

### æ–¹æ¡ˆå°æ¯”

| æ–¹æ¡ˆ | æŸ¥è©¢é€Ÿåº¦ | å­˜å„²æ•ˆç‡ | æ“´å±•æ€§ | é©ç”¨è¦æ¨¡ |
|------|---------|---------|--------|---------|
| **PostgreSQL** | æ…¢ï¼ˆ8.7sï¼‰ | å·®ï¼ˆ72 MBï¼‰ | å·® | < 100 å° |
| **å–®æ©Ÿ TSDB** | å¿«ï¼ˆ0.05sï¼‰ | å„ªï¼ˆ5 MBï¼‰ | ç„¡æ³•æ“´å±• | < 1,000 å° |
| **åˆ†ç‰‡ TSDB** | å¿« | å„ª | æ©«å‘æ“´å±• | < 10,000 å° |
| **M3/Thanos** | æ¥µå¿« | æ¥µå„ª | ç„¡é™æ“´å±• | æ•¸è¬å°+ |

### é©ç”¨å ´æ™¯

**é©åˆä½¿ç”¨ç›£æ§ç³»çµ±çš„å ´æ™¯ï¼š**
- æœå‹™å™¨ç›£æ§ï¼ˆCPUã€å…§å­˜ã€ç£ç›¤ï¼‰
- æ‡‰ç”¨ç›£æ§ï¼ˆQPSã€å»¶é²ã€éŒ¯èª¤ç‡ï¼‰
- æ¥­å‹™ç›£æ§ï¼ˆè¨‚å–®é‡ã€æ”¶å…¥ã€ç”¨æˆ¶æ´»èºï¼‰
- åŸºç¤è¨­æ–½ç›£æ§ï¼ˆæ•¸æ“šåº«ã€å¿«å–ã€æ¶ˆæ¯éšŠåˆ—ï¼‰

**ä¸é©åˆçš„å ´æ™¯ï¼š**
- æ—¥èªŒå­˜å„²ï¼ˆç”¨ ELKï¼‰
- äº‹ä»¶è¿½è¹¤ï¼ˆç”¨ Tracingï¼‰
- å…¨æ–‡æª¢ç´¢ï¼ˆç”¨ Elasticsearchï¼‰

### é—œéµæŒ‡æ¨™

```
æœ€çµ‚æ€§èƒ½ï¼ˆå–®æ©Ÿ TSDB + Gorilla + ä¸‹æ¡æ¨£ï¼‰ï¼š
- æ”¯æŒæ™‚é–“åºåˆ—ï¼š100 è¬
- å¯«å…¥ååï¼šæ¯ç§’ 10 è¬æ•¸æ“šé»
- æŸ¥è©¢å»¶é²ï¼šP99 < 100ms
- å­˜å„²æ•ˆç‡ï¼šå£“ç¸®ç‡ 11.7:1
- å‘Šè­¦å»¶é²ï¼š30 ç§’ï¼ˆè©•ä¼°é–“éš”ï¼‰

èˆ‡ PostgreSQL å°æ¯”ï¼š
- æŸ¥è©¢é€Ÿåº¦ï¼š174 å€
- å­˜å„²æ•ˆç‡ï¼š14.4 å€
- æˆæœ¬ï¼š$1,728/å¹´ â†’ $144/å¹´
```

### å»¶ä¼¸é–±è®€

**æ™‚åºæ•¸æ“šåº«ï¼š**
- Prometheusï¼ˆæœ€æµè¡Œçš„é–‹æºç›£æ§ç³»çµ±ï¼‰
- InfluxDBï¼ˆGo ç·¨å¯«çš„ TSDBï¼‰
- TimescaleDBï¼ˆåŸºæ–¼ PostgreSQL çš„æ“´å±•ï¼‰
- VictoriaMetricsï¼ˆé«˜æ€§èƒ½ TSDBï¼‰
- M3ï¼ˆUber é–‹æºçš„åˆ†å¸ƒå¼ TSDBï¼‰

**å£“ç¸®ç®—æ³•ï¼š**
- Gorillaï¼ˆFacebook, 2015ï¼‰
- Delta-of-Delta ç·¨ç¢¼
- XOR ç·¨ç¢¼

**æŸ¥è©¢èªè¨€ï¼š**
- PromQLï¼ˆPrometheus Query Languageï¼‰
- Fluxï¼ˆInfluxDB 2.0ï¼‰
- SQLï¼ˆTimescaleDBï¼‰

---

å¾ã€Œé›™11å‡Œæ™¨çš„å™©å¤¢ã€ï¼ˆæå¤± NT$ 6,300 è¬ï¼‰åˆ°ã€Œç§’ç´šç™¼ç¾å•é¡Œçš„ç›£æ§ç³»çµ±ã€ï¼ŒMetrics Monitoring ç¶“æ­·äº† 5 æ¬¡é‡å¤§æ¼”é€²ï¼š

1. **æ²’æœ‰ç›£æ§** â†’ æ‰‹å‹•æª¢æŸ¥è…³æœ¬
2. **æ•¸æ“šåº«å­˜å„²** â†’ æ™‚åºæ•¸æ“šåº«ï¼ˆ174 å€é€Ÿåº¦æå‡ï¼‰
3. **å­˜å„²æˆæœ¬** â†’ Gorilla å£“ç¸®ï¼ˆ11.7:1ï¼‰+ ä¸‹æ¡æ¨£ï¼ˆç¯€çœ 76%ï¼‰
4. **è¢«å‹•ç›£æ§** â†’ å‘Šè­¦è¦å‰‡å¼•æ“ï¼ˆç§’ç´šéŸ¿æ‡‰ï¼‰
5. **è¤‡é›œæŸ¥è©¢** â†’ PromQL æŸ¥è©¢èªè¨€

**è¨˜ä½ï¼š** ç›£æ§æ˜¯ç”Ÿç”¢ç³»çµ±çš„çœ¼ç›ã€‚æ²’æœ‰ç›£æ§ï¼Œå°±åƒè’™è‘—çœ¼ç›é–‹è»Šâ€”â€”æ—©æ™šæœƒå‡ºäº‹ã€‚å¥½çš„ç›£æ§ç³»çµ±ä¸åƒ…èƒ½åŠæ™‚ç™¼ç¾å•é¡Œï¼Œæ›´èƒ½å¹«åŠ©ä½ ç†è§£ç³»çµ±è¡Œç‚ºã€é æ¸¬æœªä¾†è¶¨å‹¢ã€æŒçºŒå„ªåŒ–æ€§èƒ½ã€‚

**æ ¸å¿ƒç†å¿µï¼š** You can't improve what you can't measure.ï¼ˆç„¡æ³•æ¸¬é‡å°±ç„¡æ³•æ”¹é€²ï¼‰
